#!/usr/bin/env bash
set -euo pipefail

# AI Processor for NXCore Shipping & Receiving System
# Integrates with Ollama to process files from the exchange system

EXCHANGE_DIR="/srv/exchange"
OLLAMA_HOST="${OLLAMA_HOST:-http://localhost:11434}"
DEFAULT_MODEL="llama3.2"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[$(date -u +%Y-%m-%dT%H:%M:%SZ)]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1" >&2
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

# Check if Ollama is running
check_ollama() {
    if ! curl -s "$OLLAMA_HOST/api/tags" >/dev/null 2>&1; then
        error "Ollama is not running at $OLLAMA_HOST"
        return 1
    fi
    return 0
}

# Generate AI response
ai_generate() {
    local model="$1"
    local prompt="$2"
    local system_prompt="${3:-}"
    
    local payload
    if [ -n "$system_prompt" ]; then
        payload=$(cat <<EOF
{
    "model": "$model",
    "prompt": "$prompt",
    "system": "$system_prompt",
    "stream": false
}
EOF
)
    else
        payload=$(cat <<EOF
{
    "model": "$model",
    "prompt": "$prompt",
    "stream": false
}
EOF
)
    fi
    
    curl -s -X POST "$OLLAMA_HOST/api/generate" \
        -H "Content-Type: application/json" \
        -d "$payload" | jq -r '.response'
}

# Process CSV file
process_csv() {
    local filepath="$1"
    local output_dir="$2"
    local model="${3:-$DEFAULT_MODEL}"
    
    log "Processing CSV: $filepath"
    
    # Read CSV content
    local content=$(cat "$filepath")
    local filename=$(basename "$filepath" .csv)
    
    # Generate analysis
    local prompt="Analyze this CSV data and provide:
1. Data structure overview
2. Key insights and patterns
3. Data quality assessment
4. Recommendations

CSV Data:
$content"
    
    local analysis=$(ai_generate "$model" "$prompt" "You are a data analyst. Provide clear, actionable insights.")
    
    # Save analysis
    local analysis_file="$output_dir/${filename}_analysis.md"
    cat > "$analysis_file" <<EOF
# CSV Analysis: $filename

**Generated:** $(date -u +%Y-%m-%dT%H:%M:%SZ)
**Model:** $model
**Source:** $filepath

## Analysis

$analysis

---
*Generated by NXCore AI Processor*
EOF
    
    success "CSV analysis saved: $analysis_file"
    echo "$analysis_file"
}

# Process text file
process_text() {
    local filepath="$1"
    local output_dir="$2"
    local model="${3:-$DEFAULT_MODEL}"
    
    log "Processing text: $filepath"
    
    local content=$(cat "$filepath")
    local filename=$(basename "$filepath")
    
    # Generate summary
    local prompt="Provide a comprehensive summary of this text document:
1. Main topics and themes
2. Key points and insights
3. Important details
4. Overall assessment

Text Content:
$content"
    
    local summary=$(ai_generate "$model" "$prompt" "You are a document analyst. Provide clear, structured summaries.")
    
    # Save summary
    local summary_file="$output_dir/${filename}_summary.md"
    cat > "$summary_file" <<EOF
# Text Summary: $filename

**Generated:** $(date -u +%Y-%m-%dT%H:%M:%SZ)
**Model:** $model
**Source:** $filepath

## Summary

$summary

---
*Generated by NXCore AI Processor*
EOF
    
    success "Text summary saved: $summary_file"
    echo "$summary_file"
}

# Process JSON file
process_json() {
    local filepath="$1"
    local output_dir="$2"
    local model="${3:-$DEFAULT_MODEL}"
    
    log "Processing JSON: $filepath"
    
    local content=$(cat "$filepath")
    local filename=$(basename "$filepath" .json)
    
    # Generate analysis
    local prompt="Analyze this JSON data and provide:
1. Data structure overview
2. Key information and patterns
3. Data relationships
4. Insights and observations

JSON Data:
$content"
    
    local analysis=$(ai_generate "$model" "$prompt" "You are a data analyst. Provide clear, structured analysis.")
    
    # Save analysis
    local analysis_file="$output_dir/${filename}_analysis.md"
    cat > "$analysis_file" <<EOF
# JSON Analysis: $filename

**Generated:** $(date -u +%Y-%m-%dT%H:%M:%SZ)
**Model:** $model
**Source:** $filepath

## Analysis

$analysis

---
*Generated by NXCore AI Processor*
EOF
    
    success "JSON analysis saved: $analysis_file"
    echo "$analysis_file"
}

# Process log file
process_log() {
    local filepath="$1"
    local output_dir="$2"
    local model="${3:-$DEFAULT_MODEL}"
    
    log "Processing log: $filepath"
    
    # Get last 100 lines for analysis
    local content=$(tail -100 "$filepath")
    local filename=$(basename "$filepath")
    
    # Generate analysis
    local prompt="Analyze this log file and provide:
1. Error patterns and issues
2. Performance insights
3. System health indicators
4. Recommendations for improvement

Log Content:
$content"
    
    local analysis=$(ai_generate "$model" "$prompt" "You are a system administrator. Focus on operational insights and issues.")
    
    # Save analysis
    local analysis_file="$output_dir/${filename}_analysis.md"
    cat > "$analysis_file" <<EOF
# Log Analysis: $filename

**Generated:** $(date -u +%Y-%m-%dT%H:%M:%SZ)
**Model:** $model
**Source:** $filepath

## Analysis

$analysis

---
*Generated by NXCore AI Processor*
EOF
    
    success "Log analysis saved: $analysis_file"
    echo "$analysis_file"
}

# Main processing function
process_file() {
    local filepath="$1"
    local output_dir="$2"
    local model="${3:-$DEFAULT_MODEL}"
    
    if [ ! -f "$filepath" ]; then
        error "File not found: $filepath"
        return 1
    fi
    
    # Check if Ollama is available
    if ! check_ollama; then
        error "Cannot process file - Ollama not available"
        return 1
    fi
    
    # Create output directory
    mkdir -p "$output_dir"
    
    # Determine file type and process accordingly
    local extension="${filepath##*.}"
    case "$extension" in
        "csv")
            process_csv "$filepath" "$output_dir" "$model"
            ;;
        "txt"|"md")
            process_text "$filepath" "$output_dir" "$model"
            ;;
        "json")
            process_json "$filepath" "$output_dir" "$model"
            ;;
        "log")
            process_log "$filepath" "$output_dir" "$model"
            ;;
        *)
            log "Unsupported file type: $extension"
            return 1
            ;;
    esac
}

# Process files from exchange system
process_exchange_files() {
    local date_dir="${1:-$(date +%Y-%m-%d)}"
    local processing_dir="$EXCHANGE_DIR/processing/$date_dir"
    local outbox_dir="$EXCHANGE_DIR/outbox/$date_dir/ai"
    
    if [ ! -d "$processing_dir" ]; then
        log "No processing directory found: $processing_dir"
        return 0
    fi
    
    log "Processing files from: $processing_dir"
    
    # Process each file
    find "$processing_dir" -type f \( -name "*.csv" -o -name "*.txt" -o -name "*.md" -o -name "*.json" -o -name "*.log" \) | while read -r file; do
        process_file "$file" "$outbox_dir"
    done
    
    success "Exchange file processing complete"
}

# Main function
main() {
    case "${1:-help}" in
        "process")
            process_file "$2" "$3" "$4"
            ;;
        "exchange")
            process_exchange_files "$2"
            ;;
        "help"|*)
            echo "NXCore AI Processor"
            echo ""
            echo "Usage: $0 <command> [options]"
            echo ""
            echo "Commands:"
            echo "  process <file> <output_dir> [model]  - Process a single file"
            echo "  exchange [date]                      - Process files from exchange system"
            echo "  help                                 - Show this help"
            echo ""
            echo "Examples:"
            echo "  $0 process data.csv /tmp/output"
            echo "  $0 process document.txt /tmp/output llama3.2"
            echo "  $0 exchange 2025-01-16"
            echo ""
            echo "Environment:"
            echo "  OLLAMA_HOST - Ollama server URL (default: http://localhost:11434)"
            echo "  EXCHANGE_DIR - Exchange directory (default: /srv/exchange)"
            ;;
    esac
}

main "$@"
